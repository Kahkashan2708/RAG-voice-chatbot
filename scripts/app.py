import os
import sys
os.environ["GITHUB_TOKEN"] = "XXXXXXXXXXXXXXXXXXXXXXX"
sys.path.insert(0, "/content/NeMo")
import gradio as gr
from task5_rag_pipeline import run_rag_pipeline


def voice_chatbot(audio_file):
    """
    Takes audio file path from Gradio,
    runs full RAG pipeline,
    returns final answer text.
    """
    if audio_file is None:
        return "âŒ Please upload an audio file (.wav)."

    try:
        answer = run_rag_pipeline(audio_file)
        return answer
    except Exception as e:
        return f"âš ï¸ Error occurred:\n{str(e)}"


with gr.Blocks(
    title="Voice-enabled RAG Chatbot",
    theme=gr.themes.Soft()
) as demo:

    gr.Markdown(
        """
        # ğŸ™ï¸ Voice-enabled RAG Chatbot
        ### Hindi Speech â†’ AI-powered Answer

        This application performs:
        - ğŸ§ **Automatic Speech Recognition (IndicConformer)**
        - ğŸŒ **Hindi â†’ English Translation**
        - ğŸ“š **Context Retrieval using FAISS Vector DB**
        - ğŸ¤– **Answer Generation using LLM (GitHub Models)**

        Upload a **Hindi audio (.wav)** file and get an intelligent answer.
        """
    )

    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(
                type="filepath",
                label="ğŸ§ Upload Audio (.wav)",
                interactive=True
            )

            submit_btn = gr.Button(
                "ğŸš€ Ask Question",
                variant="primary"
            )

        with gr.Column(scale=1):
            output_text = gr.Textbox(
                label="ğŸ¤– Chatbot Answer",
                lines=10,
                interactive=False,
                placeholder="The answer will appear here..."
            )

    submit_btn.click(
        fn=voice_chatbot,
        inputs=audio_input,
        outputs=output_text
    )

    gr.Markdown(
        """
        ---
        **Tech Stack:**
        NeMo IndicConformer Â· FastAPI Â· FAISS Â· LangChain Â· Gradio Â· GitHub Models
        """
    )
demo.launch(share=True)



